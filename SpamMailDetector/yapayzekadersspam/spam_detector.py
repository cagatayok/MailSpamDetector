import re
import pickle
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import numpy as np

# Flask importlarÄ±
from flask import Flask, request, jsonify
from flask_cors import CORS
import os


class EmailSpamDetector:
    """GerÃ§ek veri seti ile spam tespit eden makine Ã¶ÄŸrenimi sÄ±nÄ±fÄ±."""

    def __init__(self, model_type='naive_bayes'):
        """
                Args:
                    model_type: 'naive_bayes', 'logistic_regression', 'random_forest'
                """
        self.vectorizer = TfidfVectorizer(  #metin verilerinde hangi kelimelerin onemli oldugunu bulmak icin kullanilir
            max_features=3000,
            min_df=2,
            max_df=0.8,
            ngram_range=(1, 2),   #1 ve 2 kelimeden olusan ifadeleri kullanir(unigram ve bigram)
            stop_words='english'
        )
        # Model seÃ§imi
        if model_type == 'naive_bayes':
            self.model = MultinomialNB()
        elif model_type == 'logistic_regression':  #olasilikk hesaplamasi guclu,daha dengeli sonuclar verir
            self.model = LogisticRegression(max_iter=1000)
        elif model_type == 'random_forest':    #birden fazla karar agaci kullanir,karmasik iliskileri yakalar
            self.model = RandomForestClassifier(
                n_estimators=100,
                random_state=42
            )
        else:
            raise ValueError("GeÃ§ersiz model tipi!")

        self.model_type = model_type
        self.is_trained = False

    def preprocess_email(self, text):               # makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n daha verimli Ã§alÄ±ÅŸabilmesi iÃ§in
        text = str(text).lower()         # TÃ¼m metinler kÃ¼Ã§Ã¼k harfe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmektedir.
        text = re.sub(r'http\S+|www\S+|https\S+', 'URL', text)
        text = re.sub(r'\S+@\S+', 'EMAIL', text)
        text = re.sub(r'\d+', 'NUM', text)
        text = re.sub(r'[^\w\s]', ' ', text)    # Noktalama iÅŸaretleri kaldÄ±rÄ±lmakta ve gereksiz boÅŸluklar temizlenmektedir.
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def extract_features(self, emails):
        """E-postalardan Ã¶zellik Ã§Ä±karÄ±mÄ±"""  # Makine Ã¶ÄŸrenmesi algoritmalarÄ± metin verilerini doÄŸrudan anlayamaz.
        # sayÄ±sal vektorlere donusturulur
        processed_emails = [self.preprocess_email(email) for email in emails]
        if not self.is_trained:
            features = self.vectorizer.fit_transform(processed_emails)
        else:
            features = self.vectorizer.transform(processed_emails)
        return features

    def load_dataset(self, source='uci'):    #********* VERÄ° SETÄ° YÃœKLENÄ°R*************

        """
                Veri setini yÃ¼kle
                Args:
                    source: 'uci' (otomatik indir) veya 'local' (yerel dosya)
                """
        print("Veri seti yÃ¼kleniyor...")

        if source == 'uci':
            try:

                # UCI'den otomatik indirme
                from ucimlrepo import fetch_ucirepo
                sms_spam = fetch_ucirepo(id=228)
                X = sms_spam.data.features['sms'].values # mesaj girdisi
                y = sms_spam.data.targets['label'].values # mesaj ciktisi
                # spam/ham -> 1/0 dÃ¶nÃ¼ÅŸÃ¼mÃ¼ makine Ã¶grenme stringle deÄŸil sayÄ±sal olmalÄ±
                y = np.array([1 if label == 'spam' else 0 for label in y])
                print(f"âœ“ {len(X)} mesaj UCI'den yÃ¼klendi.")
            except Exception as e: # hata yakalanÄ±rsa kod devam eder alternatif veri kaynagÄ±na yonlendÄ±rme
                print(f"UCI HatasÄ±: {e}")
                return self._load_from_kaggle()
        elif source == 'local':
            # Yerel CSV dosyasÄ±ndan yÃ¼kleme
            df = pd.read_csv('spam.csv', encoding='latin-1') # Bu dosyayÄ± Latin-1 karakter kodlamasÄ±yla oku
            df = df[['v1', 'v2']]
            df.columns = ['label', 'message']
            X = df['message'].values
            y = df['label'].map({'spam': 1, 'ham': 0}).values
            print(f"âœ“ {len(X)} mesaj yerel dosyadan yÃ¼klendi.")
        return X, y

    def _load_from_kaggle(self):
        """Kaggle'dan alternatif yÃ¼kleme"""
        try:
            url = "https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv"
            df = pd.read_csv(url, sep='\t', header=None, names=['label', 'message'])
            X = df['message'].values
            y = df['label'].map({'spam': 1, 'ham': 0}).values
            print(f"âœ“ {len(X)} mesaj GitHub'dan yÃ¼klendi.")
            return X, y
        except Exception as e:
            print(f"Alternatif kaynak hatasÄ±: {e}")
            raise Exception("Veri seti yÃ¼klenemedi!")

    def train_with_dataset(self, test_size=0.2, show_details=True):
        """GerÃ§ek veri seti ile modeli eÄŸit"""
        # Veri setini yÃ¼kle
        X, y = self.load_dataset()

        # Veri analizi
        if show_details:
            self._show_dataset_stats(X, y)

        # EÄŸitim/test ayrÄ±mÄ±
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )

        print(f"\nğŸ”„ Model eÄŸitiliyor (model: {self.model_type})...")
        # Ã–zellikleri Ã§Ä±kar
        X_train_features = self.extract_features(X_train)
        self.is_trained = True
        X_test_features = self.extract_features(X_test)

        # Modeli eÄŸit
        self.model.fit(X_train_features, y_train)

        # Tahmin yap
        y_pred = self.model.predict(X_test_features)
        # SonuÃ§larÄ± gÃ¶ster
        accuracy = accuracy_score(y_test, y_pred)

        print("\n" + "=" * 70)
        print("ğŸ“Š MODEL PERFORMANSI")
        print("=" * 70)
        print(f"DoÄŸruluk: {accuracy:.4f} ({accuracy * 100:.2f}%)")
        print("\nDetaylÄ± SÄ±nÄ±flandÄ±rma Raporu:")
        print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))

        cm = confusion_matrix(y_test, y_pred)
        print("\nKarÄ±ÅŸÄ±klÄ±k Matrisi:")
        print(f"                Tahmin")
        print(f"              Ham    Spam")
        print(f"GerÃ§ek Ham   {cm[0][0]:4d}   {cm[0][1]:4d}")
        print(f"       Spam  {cm[1][0]:4d}   {cm[1][1]:4d}")

        if show_details:
            print("\nğŸ”„ Cross-validation yapÄ±lÄ±yor...")
            cv_scores = cross_val_score(self.model, self.extract_features(X), y, cv=5)
            print(f"CV SkorlarÄ±: {cv_scores}")
            print(f"Ortalama CV Skoru: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

        return accuracy

    def _show_dataset_stats(self, X, y):
        print("\n" + "=" * 70)
        print("ğŸ“ˆ VERÄ° SETÄ° ANALÄ°ZÄ°")
        print("=" * 70)
        print(f"Toplam mesaj: {len(X)}")
        print(f"Spam mesaj: {sum(y)} (%{sum(y) / len(y) * 100:.1f})")
        print(f"Normal mesaj: {len(y) - sum(y)} (%{(len(y) - sum(y)) / len(y) * 100:.1f})")

        spam_lengths = [len(X[i]) for i in range(len(X)) if y[i] == 1]
        ham_lengths = [len(X[i]) for i in range(len(X)) if y[i] == 0]

        print("\nOrtalama mesaj uzunluklarÄ±:")
        print(f"  Spam: {np.mean(spam_lengths):.0f} karakter")
        print(f"  Normal: {np.mean(ham_lengths):.0f} karakter")

        print("\nğŸ“§ Ã–rnek Spam MesajÄ±:")
        for msg in [X[i] for i in range(len(X)) if y[i] == 1][:2]:
            print(" -", msg[:120], "...")

        print("\nğŸ“§ Ã–rnek Normal Mesaj:")
        for msg in [X[i] for i in range(len(X)) if y[i] == 0][:2]:
            print(" -", msg[:120], "...")

    def predict(self, email):
        if not self.is_trained:
            raise Exception("Model eÄŸitilmedi!")

        features = self.extract_features([email])
        prediction = self.model.predict(features)[0]
        probability = self.model.predict_proba(features)[0]

        return {
            'is_spam': bool(prediction),
            'spam_probability': float(probability[1]),
            'normal_probability': float(probability[0]),
            'confidence': float(max(probability))
        }

    def predict_batch(self, emails):
        if not self.is_trained:
            raise Exception("Model eÄŸitilmedi!")

        features = self.extract_features(emails)
        predictions = self.model.predict(features)
        probabilities = self.model.predict_proba(features)

        results = []
        for i, email in enumerate(emails):
            results.append({
                'email': email[:100] + '...' if len(email) > 100 else email,
                'is_spam': bool(predictions[i]),
                'spam_probability': float(probabilities[i][1]),
                'confidence': float(max(probabilities[i]))
            })
        return results

    def save_model(self, filepath='real_spam_model.pkl'):
        if not self.is_trained:
            raise Exception("Model henÃ¼z eÄŸitilmedi!")

        with open(filepath, 'wb') as f:                     # Bu fonksiyon eÄŸitilmiÅŸ modeli kalÄ±cÄ± hale getirir
#Yani â€œÃ¶ÄŸrenilen her ÅŸeyi dosyaya yaz ve saklaâ€ iÅŸi yapar.
#Bu fonksiyon, eÄŸitilmiÅŸ spam tespit modelini .pkl dosyasÄ± olarak diske kaydeder.
            pickle.dump({
                'vectorizer': self.vectorizer,
                'model': self.model,
                'model_type': self.model_type,
                'is_trained': self.is_trained
            }, f)
        print(f"\nâœ“ Model baÅŸarÄ±yla kaydedildi: {filepath}")

    def load_model(self, filepath='real_spam_model.pkl'):
        with open(filepath, 'rb') as f:
            data = pickle.load(f)
            self.vectorizer = data['vectorizer']
            self.model = data['model']              # EÄTÄ°LEN DOSYAMIZI AÃ‡AR VE GEREKLÄ° Ã–ZELLÄ°KLERÄ°NÄ° ALARAK BELLEÄE YERLEÅTÄ°RÄ°R.
                                                    # MODELÄ° HER SEFERÄ°NDE EÄÄ°TMEK YERÄ°NE,
                                                    # HAZIR EÄÄ°TÄ°LMÄ°Å MODELÄ°N NASIL YÃœKLENECEÄÄ°NÄ° TANIMLAR.
            self.model_type = data['model_type']
            self.is_trained = data['is_trained']
        print(f"âœ“ Model yÃ¼klendi: {filepath}")


# ============================================================================
# FLASK API UYGULAMASI
# ============================================================================

app = Flask(__name__)             #/////////////////// KODU APÄ° Ä°LE BÄ°RLÄ°KTE BACKEND SUNUCUSUNA Ã‡EVÄ°RÄ°YOR **********************
CORS(app)  # React'ten gelen isteklere izin ver

# Global model deÄŸiÅŸkeni
detector = None
MODEL_PATH = 'spam_model_real.pkl'


def init_model():
    """Uygulama baÅŸlarken modeli yÃ¼kle veya eÄŸit"""
    global detector

    print("\n" + "=" * 70)
    print("ğŸš€ SPAM DETECTOR API BAÅLATILIYOR")
    print("=" * 70)

    detector = EmailSpamDetector(model_type='naive_bayes')

    # EÄŸer kaydedilmiÅŸ model varsa onu yÃ¼kle
    if os.path.exists(MODEL_PATH):
        try:                                              # APÄ° AYAÄA KALKARKEN MODELÄ° KONTROL EDER MODEL VAR MI EÄÄ°TÄ°LMÄ°Å MÄ°
            print(f"\nğŸ“¦ KaydedilmiÅŸ model bulundu: {MODEL_PATH}")
            detector.load_model(MODEL_PATH)
            print("âœ… Model baÅŸarÄ±yla yÃ¼klendi!")
        except Exception as e:
            print(f"âŒ Model yÃ¼klenemedi: {e}")
            print("ğŸ”„ Yeni model eÄŸitiliyor...")
            train_new_model()    # model yoksa model eÄŸitme fonksiyonunu Ã§aÄŸÄ±rÄ±yor
    else:
        print("\nâš ï¸  KaydedilmiÅŸ model bulunamadÄ±.")
        print("ğŸ”„ Yeni model eÄŸitiliyor...")
        train_new_model()

    print("\nâœ… API hazÄ±r!")
    print("=" * 70)


def train_new_model():                      # ********MODEL EÄÄ°TME FONKSÄ°YONU**********
    """Yeni model eÄŸit ve kaydet"""
    global detector
    try:
        detector.train_with_dataset(test_size=0.2, show_details=True)     # ***** Model eÄŸitiliyor demek:
        # #BilgisayarÄ±n, spam ve normal e-postalarda hangi kelimelerin ne sÄ±klÄ±kla geÃ§tiÄŸini
        # #Ã¶ÄŸrenmesi ve bu bilgiyi sayÄ±sal kurallar haline getirmesi demektir.***************
        detector.save_model(MODEL_PATH)
    except Exception as e:
        print(f"âŒ Model eÄŸitimi baÅŸarÄ±sÄ±z: {e}")
        raise


@app.route('/')
def home():
    """API ana sayfasÄ±"""
    return jsonify({
        'message': 'Spam Detector API',
        'version': '1.0',                               # APÄ°YE TARAYICIDAN GÄ°RÄ°LÄ°NCE BÄ°LGÄ°LENDÄ°RME DÃ–NER
        'endpoints': {
            '/api/analyze': 'POST - Tek mesaj analizi',
            '/api/batch': 'POST - Toplu mesaj analizi',
            '/api/status': 'GET - Model durumu',
            '/api/retrain': 'POST - Modeli yeniden eÄŸit'
        }
    })


@app.route('/api/status')
def status():
    """Model durumunu kontrol et"""
    if detector and detector.is_trained:
        return jsonify({
            'status': 'ready',
            'model_type': detector.model_type,              # MODELÄ°N DURUMUNU KONTOL EDER
            'is_trained': detector.is_trained
        })
    else:
        return jsonify({
            'status': 'not_ready',
            'message': 'Model eÄŸitilmedi'
        }), 503


@app.route('/api/analyze', methods=['POST'])
def analyze():
    """Tek bir e-posta mesajÄ±nÄ± analiz et"""
    try:
        data = request.json

        if not data or 'email' not in data:                     # TEK BÄ°R E POSTANIN SPAM OLUP OLMADIÄINI TAHMÄ°N EDER
            return jsonify({
                'error': 'Email metni gerekli',
                'success': False
            }), 400

        email_text = data['email']

        if not email_text.strip():
            return jsonify({
                'error': 'Email metni boÅŸ olamaz',
                'success': False
            }), 400

        # Model kontrolÃ¼
        if not detector or not detector.is_trained:
            return jsonify({
                'error': 'Model henÃ¼z eÄŸitilmedi',
                'success': False
            }), 503

        # Tahmin yap
        result = detector.predict(email_text)
        result['success'] = True                    # GÄ°RÄ°LEN E POSTAYA Ã‡IKARILAN SONUÃ‡LARA GÃ–RE TAHMÄ°N YAPAR
        result['timestamp'] = pd.Timestamp.now().isoformat()

        return jsonify(result)

    except Exception as e:
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@app.route('/api/batch', methods=['POST'])
def batch_analyze():
    """Birden fazla e-postayÄ± analiz et"""              # BURADA DA BÄ°RDEN FAZLA E POSTAYI ANALÄ°Z EDER
    try:
        data = request.json

        if not data or 'emails' not in data:
            return jsonify({
                'error': 'Emails listesi gerekli',
                'success': False
            }), 400

        emails = data['emails']

        if not isinstance(emails, list):
            return jsonify({
                'error': 'Emails bir liste olmalÄ±',
                'success': False
            }), 400

        if len(emails) == 0:
            return jsonify({
                'error': 'Email listesi boÅŸ',
                'success': False
            }), 400

        if len(emails) > 100:
            return jsonify({
                'error': 'Maksimum 100 email analiz edilebilir',
                'success': False
            }), 400

        # Model kontrolÃ¼
        if not detector or not detector.is_trained:
            return jsonify({
                'error': 'Model henÃ¼z eÄŸitilmedi',
                'success': False
            }), 503

        # Toplu tahmin
        results = detector.predict_batch(emails)

        return jsonify({
            'success': True,
            'count': len(results),
            'results': results,
            'timestamp': pd.Timestamp.now().isoformat()
        })

    except Exception as e:
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@app.route('/api/retrain', methods=['POST'])
def retrain():
    """Modeli yeniden eÄŸit"""
    try:
        print("\nğŸ”„ Model yeniden eÄŸitiliyor...")            # MODELÄ° MANUEL OLARAK EÄÄ°TÄ°LMESÄ°NE OLANAK SAÄLAR
        train_new_model()

        return jsonify({
            'success': True,
            'message': 'Model baÅŸarÄ±yla yeniden eÄŸitildi',
            'model_type': detector.model_type
        })

    except Exception as e:
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'error': 'Endpoint bulunamadÄ±',             # HATA YÃ–NETÄ°MÄ° YAPILIR
        'success': False
    }), 404


@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'error': 'Sunucu hatasÄ±',
        'success': False
    }), 500


# ============================================================================
# UYGULAMA BAÅLATMA
# ============================================================================

if __name__ == "__main__":
    # Modeli baÅŸlat
    init_model()

    # Flask sunucusunu baÅŸlat
    print("\nğŸŒ Flask sunucusu baÅŸlatÄ±lÄ±yor...")
    print("ğŸ“ URL: http://localhost:5000")
    print("ğŸ›‘ Durdurmak iÃ§in: CTRL+C\n")

    app.run(
        debug=True,
        host='0.0.0.0',
        port=5000,
        use_reloader=False  # Model iki kez yÃ¼klenmesin
    )